\documentclass[sigconf]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{\BibTeX}}}

%% Minimal rights info for course work (adjust if your lecturer gave you specific text)
\setcopyright{none}
\copyrightyear{2025}
\acmYear{2025}
%% \acmDOI{10.0000/placeholder-doi}

\acmConference[Seminar Human–Agent Collaboration]{Main Seminar on Human–Agent Collaboration}{Winter Term 2025}{Munich, Germany}
%% \acmISBN{000-0-0000-0000-0/25/00}

%% Classification (can be refined if needed)
\begin{CCSXML}
<ccs2012>
  <concept>
    <concept_id>10003120.10003121.10003122.10003334</concept_id>
    <concept_desc>Human-centered computing~Collaborative interaction</concept_desc>
    <concept_significance>500</concept_significance>
  </concept>
  <concept>
    <concept_id>10010147.10010178.10010219.10010223</concept_id>
    <concept_desc>Computing methodologies~Natural language processing</concept_desc>
    <concept_significance>300</concept_significance>
  </concept>
  <concept>
    <concept_id>10002951.10003317.10003359.10003360</concept_id>
    <concept_desc>Information systems~Information retrieval</concept_desc>
    <concept_significance>300</concept_significance>
  </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Collaborative interaction}
\ccsdesc[300]{Computing methodologies~Natural language processing}
\ccsdesc[300]{Information systems~Information retrieval}

\keywords{large language models, human–agent collaboration, context windows, retrieval augmented generation, summarization, memory}

\title[Context Handling Mechanisms in Human Agent Collaboration]{Context Handling Mechanisms in Human Agent Collaboration: Sequencing, Retrieval, Summarization and Context Window Size}

\author{Lukas Röß}
\affiliation{%
  \institution{Munich University of Applied Sciences}
  \city{Munich}
  \country{Germany}}
\email{lukas.roess@hm.edu}

\renewcommand{\shortauthors}{L. Röß}

\begin{document}

\begin{abstract}
Large language models act as agents in human–AI collaboration across domains such as analysis, writing and decision support. In these settings, humans and agents interact over many turns. The agent must keep track of prior content, refer back to earlier decisions and adapt to changing goals. This need shifts attention from single prompt accuracy to sustained context handling.

Research explores several mechanisms to manage context, including multi agent sequencing, retrieval augmented generation, summarization and extended context windows. Most work evaluates these mechanisms in isolation or on technical benchmarks. Less is known about how they jointly affect collaboration between humans and agents.

This paper synthesizes recent work from 2024 and 2025 on long context processing, memory architectures and human–agent collaboration. It reviews multi agent sequencing approaches such as Chain of Agents, Graph of Agents and XpandA, which divide long inputs across agents and recombine their outputs. It contrasts these methods with empirical comparisons of retrieval augmented generation and long context models in industrial and clinical applications. It also integrates work on memory structures, summarization strategies and studies of human teams supported by AI summarizers.

Based on this synthesis, the paper proposes a framework that links four context handling mechanisms, namely sequencing, retrieval, summarization and context window size, to three dimensions of collaboration effectiveness: task performance, interaction quality and long-term consistency. It refines the research question for the seminar project to: How do different mechanisms of context handling, such as sequencing, retrieval, summarization and context window size, jointly influence the effectiveness of human–agent collaboration?
\end{abstract}

\maketitle

\section{Introduction}

Large language models (LLMs) have shifted from static tools to agents that participate in ongoing collaboration with humans. In domains such as analysis, writing and decision support, humans and LLM agents exchange information over extended interactions. The agent must keep relevant context, recover prior steps and adapt to updated goals, not only respond to isolated prompts.

A central technical and design question concerns how LLM based agents handle context. One approach extends the context window of a single model. Longer windows allow direct conditioning on long inputs but face limits such as attention dilution and reduced use of early tokens. Multi agent approaches therefore explore sequencing and division of labour. Chain of Agents processes long inputs by passing segments through worker agents and uses a manager agent to integrate their outputs. This method improves performance over retrieval based and full context baselines on long context tasks \cite{zhang2024chainofagents}. Graph of Agents generalizes this idea by constructing dynamic collaboration graphs and frames long context processing as a compression problem. It often outperforms both retrieval augmented generation and fixed multi agent baselines while using short local windows \cite{joo2025graphofagents}. XpandA introduces a question driven multi agent framework that partitions long texts, coordinates agents through a shared memory and processes sequences of up to one million tokens with competitive accuracy and latency \cite{xiao2025xpanda}.

Other work compares retrieval augmented generation and long context models in applied settings. An industry study reports that long context models outperform retrieval augmented generation when resources permit, while retrieval remains more cost efficient and can be paired with long context models through routing strategies \cite{li2024ragvslc}. In the medical domain, a question answering study shows that long context retrieval architectures can counter the usual performance drop for information in the middle of a long sequence and improve answer quality over standard retrieval pipelines \cite{zhang2025leveraging}.

Beyond capacity, memory mechanisms and summarization strategies play a key role. A recent survey reviews memory mechanisms for LLM agents, including short term context, long term and external memory. It argues that memory design must reflect the dynamics of human interaction \cite{zhang2025memorysurvey}. Work on contextual memory intelligence treats memory as system infrastructure that captures decisions and their context over time. It aims to support reflection, accountability and stable collaboration \cite{wedel2025cmi}. Empirical work from DeepMind studies how collaboration modes and memory banks interact with chain of thought and multi agent setups. The findings show that exemplar retrieval and memory can distract models in some tasks instead of supporting them \cite{michelman2025enhancing}.

Studies of human teams with AI support complement these technical perspectives. An experiment with virtual collaborative analysis compares two AI summarizers. Summary style affects trust and attention patterns even when problem solving accuracy remains similar \cite{kane2025virtual}. Another study of student interactions with LLMs on complex tasks finds that interaction patterns often reduce to instruct–serve–repeat cycles with long threads that reveal misalignment between human intent and model output \cite{saqr2025humancollab}.

These results indicate that context handling concerns more than the size of the context window. Sequencing, retrieval, summarization and memory design interact with human trust, attention and perceived agency. Yet most work evaluates these mechanisms separately or with a narrow focus on model performance. Integrated accounts of how context handling mechanisms jointly shape human–agent collaboration remain scarce.

This project addresses this gap through the following research question.

\medskip
\textbf{Research question.} \emph{How do different mechanisms of context handling, such as sequencing, retrieval, summarization and context window size, jointly influence the effectiveness of human–agent collaboration?}

\medskip
The paper contributes to the seminar project in three ways. First, it summarizes recent work on long context processing, memory and collaboration into a structured view of context handling mechanisms. Second, it relates these mechanisms to dimensions of collaboration effectiveness that are relevant for human–agent teaming. Third, it outlines a research design that will guide the empirical phase of the project in the next milestone.

\section{Background}

\subsection{Human–agent collaboration with LLMs}

Human–agent collaboration arises when humans and artificial agents work on tasks with shared goals, roles and responsibilities. Modern LLM based agents can generate text, reason over documents, call tools and maintain conversational histories. These abilities support scenarios in which the agent acts as a partner rather than as an oracle that answers one isolated query.

Empirical work shows that current systems still fall short of this ambition. An analysis of student interaction sequences with LLM based tools in a complex problem solving task finds that most interactions follow an instruct–serve–repeat pattern. Students issue instructions, the AI responds and the pattern repeats. Negotiation, joint sensemaking and mutual adaptation remain rare \cite{saqr2025humancollab}. The system records long conversational histories but uses them in a limited way for deeper collaboration.

Research on human teams with AI summarizers suggests that context handling can shape collaboration processes. In a virtual team experiment, an AI summarizer produced either informative or indicative summaries of shared documents. Problem solving accuracy remained similar across conditions. However, informative summaries increased trust in the AI and changed how often and how quickly participants attended to teammate information \cite{kane2025virtual}. Summary style thus affected trust and attention, which matter for effective collaboration.

These findings motivate a closer focus on context handling mechanisms in LLM agents and how they relate to human behaviour and perception, not only to model accuracy.

\subsection{Context representation and memory in LLM agents}

From a technical view, LLMs handle context through four main strategies relevant to this project. The first is extended context windows that allow more tokens as direct input. The second is retrieval augmented generation, which retrieves documents or conversation snippets from external stores and injects them into a smaller window. The third is summarization, which compresses prior content into shorter representations. The fourth is explicit memory architectures that preserve information beyond a single prompt–response cycle.

A survey on memory mechanisms for LLM based agents distinguishes short term rolling context, episodic memory in vector stores, semantic memory graphs, parametric memory via fine tuning and hybrid memory controllers. It emphasizes that memory systems must decide what to store, when to update and how to retrieve information for different tasks and collaboration patterns \cite{zhang2025memorysurvey}. This view supports the idea that sequencing, retrieval and summarization form components of a broader memory system.

Work on contextual memory intelligence extends this notion and treats memory as a system level capability for generative AI. It proposes a layered architecture with an insight layer that captures decisions, rationales and environmental signals over time. The design includes human review and drift detection and aims to support coherent collaboration in organizational settings \cite{wedel2025cmi}. This work connects memory design to social and institutional contexts instead of narrow benchmarks.

Empirical work on collaboration and memory highlights trade offs. A DeepMind study compares fixed, random and similarity based retrieval of exemplars, and frozen versus learned memory banks, in multi agent reasoning tasks. Similarity based retrieval does not dominate random selection on all tasks. In some cases, any exemplars reduce performance \cite{michelman2025enhancing}. These results caution against the assumption that more memory or more complex retrieval always improve reasoning or collaboration.

\subsection{Mechanisms of context handling}

This project focuses on four context handling mechanisms that recur across the literature.

\textbf{Sequencing.}
Sequencing structures processing as a sequence of steps, often across several agents with specific roles. Chain of Agents introduces worker agents that process segments of a long input and a manager agent that synthesizes their outputs. This design exploits long documents while giving each agent a short local window \cite{zhang2024chainofagents}. Graph of Agents formalizes long context processing as a compression problem and builds dynamic graphs in which agents iteratively exchange and refine information under an information theoretic objective \cite{joo2025graphofagents}. XpandA uses a question driven workflow and shared memory. It partitions ultra long texts and lets agents update a central ensemble of information, which supports processing of sequences up to one million tokens \cite{xiao2025xpanda}.

\textbf{Retrieval.}
Retrieval augmented generation fetches relevant documents, conversation segments or exemplars from external stores and passes them to the model within a limited window. The EMNLP industry study benchmarks retrieval augmented generation and long context models on several datasets. It finds that long context models reach higher average performance when model and hardware resources allow, while retrieval remains more cost efficient. A hybrid routing method that directs queries either to retrieval augmented pipelines or to long context inference achieves near long context performance at reduced cost \cite{li2024ragvslc}. The medical question answering study combines retrieval with long context representations and reduces the typical performance loss for information in the middle of long sequences, which improves answer quality \cite{zhang2025leveraging}. This result shows that context window size and retrieval can act as complementary mechanisms.

\textbf{Summarization.}
Summarization compresses content so that systems can store and share more information under context limits. In multi agent systems, summarization shapes both internal state and communication between agents. Chain of Agents relies on the manager agent to summarize worker outputs into a final answer \cite{zhang2024chainofagents}. Graph of Agents uses compression objectives to guide how agents summarize and pass information along edges \cite{joo2025graphofagents}. XpandA maintains summarized ensembles of information in a central memory and replays partitions when needed \cite{xiao2025xpanda}. In human teams, AI summarizers control which information humans see and when, and thus influence attention and trust \cite{kane2025virtual}.

\textbf{Context window size.}
Context window size determines how many tokens a model can process in one pass. Extended windows allow direct conditioning on long histories but do not ensure effective use of earlier content. Studies on long context models show that performance gains depend on task structure and input distribution. The EMNLP industry study reports that long context models outperform retrieval augmented generation when resources are sufficient and that hybrid routing is needed under cost constraints \cite{li2024ragvslc}. The medical study shows that long context retrieval pipelines can leverage extended windows to improve clinical question answering \cite{zhang2025leveraging}. Multi agent approaches such as Graph of Agents show how collaboration architectures can surpass much larger windows by distributing processing across small local windows \cite{joo2025graphofagents}.

These four mechanisms form the conceptual basis for the analysis and research design in the remainder of the project.

\section{Related work}

\subsection{Sequencing and multi agent collaboration}

Multi agent approaches treat an LLM based system as a team of agents. Each agent handles part of the context or reasoning process. Chain of Agents introduces a design in which worker agents process segments of a long document in sequence and communicate their findings. A manager agent aggregates these findings and produces a final answer. Experiments on long context question answering, summarization and code completion show that this approach outperforms retrieval augmented generation, full context operation and other multi agent baselines, even though each agent has a short local window \cite{zhang2024chainofagents}. Sequencing thus compensates for limited context capacity.

Graph of Agents extends this design through dynamic graphs of agents. The communication pattern follows an information theoretic compression objective rather than a fixed chain. Agents connect according to input structure and refine compressed representations over iterations. On long context question answering benchmarks, this method improves F1 scores over retrieval augmented generation and a strong fixed multi agent baseline and increases effective context beyond the base model limit \cite{joo2025graphofagents}. Emergent collaboration structures in the graph appear more effective than hand crafted pipelines.

XpandA targets ultra long sequences. It partitions texts so that each partition fills the context window to a set degree. Agents follow a question driven workflow and update a shared memory that stores an ensemble of information. Agents replay partitions when needed to resolve temporal structures such as flashbacks. XpandA improves accuracy and inference speed over full context models, retrieval augmented generation and previous agent based methods on long context tasks \cite{xiao2025xpanda}. It illustrates how sequencing, shared memory and dynamic partitioning support long context processing.

\subsection{Retrieval augmented generation and long context models}

The trade off between retrieval augmented generation and extended context windows is central for context handling. The EMNLP industry study compares these strategies with several contemporary LLMs across diverse datasets. Long context models achieve higher average performance when model and hardware resources are provisioned. Retrieval augmented generation remains attractive due to cost. The study proposes a hybrid routing method in which the system sends queries either to retrieval augmented pipelines or to long context inference based on model self reflection. This method approaches long context performance at lower cost \cite{li2024ragvslc}. The work quantifies trade offs between context capacity and retrieval in realistic conditions.

In the clinical domain, long context retrieval architectures support medical question answering. The npj Digital Medicine paper combines retrieval augmented language models with extended context windows and designs a method that reduces the performance drop for information in the middle of long contexts. The system uses long context representations with retrieval and improves answer quality on clinical datasets compared to standard retrieval augmented generation baselines \cite{zhang2025leveraging}. This result shows that context window size and retrieval can act as complementary mechanisms.

These studies suggest that effective human–agent collaboration in high stakes domains will use hybrid systems that decide when to retrieve, when to rely on long context and how to combine both within an interaction.

\subsection{Memory architectures and summarization}

Memory architectures aim to preserve information across interactions and tasks. The survey on memory mechanisms for LLM based agents reviews sliding window context, episodic memory in vector stores, semantic memory graphs, learned key–value caches and other structures. It organizes these mechanisms by retention horizon and access pattern and describes a tension between storing rich context and avoiding distraction from outdated content \cite{zhang2025memorysurvey}. The survey supports a view in which sequencing, retrieval, summarization and window size form parts of a memory system.

Contextual memory intelligence introduces a normative perspective on memory design. It argues that memory should support coherent behaviour, explanation and governance in organizational settings. The proposed insight layer captures decisions, rationales and environment changes and integrates human review and drift detection \cite{wedel2025cmi}. Memory becomes a core element for human–agent collaboration that must remain aligned with institutional constraints over time. This view motivates the inclusion of collaboration effectiveness metrics beyond accuracy.

DeepMind’s empirical work on collaboration and memory links these concepts to performance outcomes. The study varies collaboration styles, memory bank designs and retrieval methods in controlled tasks and measures reasoning performance. Chain of thought prompting, multi agent collaboration and memory banks interact in complex ways. Similarity based retrieval does not always outperform random exemplar selection, and memory can reduce performance in some tasks \cite{michelman2025enhancing}. These findings show that memory and summarization mechanisms require evaluation in the context of specific tasks and collaboration patterns.

\subsection{Human teams with AI support}

Research on small groups provides further insight into AI mediated context handling. In the virtual collaborative analysis study, teams used a platform with an AI summarizer that produced either informative or indicative summaries of shared documents. Participants who received informative summaries reported higher trust in the AI and showed different attention patterns to teammate information. Problem solving accuracy stayed similar across conditions \cite{kane2025virtual}. Summary style thus shaped social dynamics and perceptions even when task level outcomes were stable.

Another study examines how students interact with LLM systems while solving a complex task. Sequence and network analysis show that interaction patterns cluster around simple instruct–serve–repeat dynamics. Long message threads reveal sustained misalignment between prompts and AI responses, and the study does not find a strong link between assignment complexity, prompt length and performance \cite{saqr2025humancollab}. The findings suggest that current LLM systems, tuned for instruction following, do not yet act as strong partners for cognitive collaboration.

These results underline that context handling mechanisms act as design levers for trust, attention and perceived agency in human–agent collaboration, not only for task accuracy.

\section{Conceptual framework}

Based on the reviewed literature, this section proposes a framework that relates context handling mechanisms to collaboration effectiveness.

The framework considers four mechanisms: sequencing, retrieval, summarization and context window size. It examines their influence along three dimensions of collaboration effectiveness.

\textbf{Task performance.}
This dimension covers accuracy, completeness and efficiency on joint tasks. Multi agent sequencing improves performance on long context question answering and summarization compared to retrieval augmented baselines \cite{zhang2024chainofagents,joo2025graphofagents,xiao2025xpanda}. Long context retrieval architectures increase answer quality in medical question answering \cite{zhang2025leveraging}. Hybrid routing between retrieval and long context reaches near long context performance at reduced cost \cite{li2024ragvslc}.

\textbf{Interaction quality.}
This dimension describes trust, attention and communication patterns in human–agent teaming. Informative AI summaries raise trust and change attention to teammate information \cite{kane2025virtual}. In contrast, studies of real world interactions with LLMs report limited negotiation and misalignment between human intent and AI output \cite{saqr2025humancollab}. Memory and summarization mechanisms can support or hinder coordinated reasoning in multi agent systems \cite{michelman2025enhancing}.

\textbf{Longitudinal alignment.}
This dimension concerns coherence and alignment over extended periods. Memory surveys and contextual memory intelligence describe memory mechanisms that maintain stable yet adaptable representations of context, decisions and rationales \cite{zhang2025memorysurvey,wedel2025cmi}. Multi agent frameworks such as XpandA show how shared memory and partition replay preserve consistency across very long inputs \cite{xiao2025xpanda}.

The refined research question asks how different combinations of the four mechanisms affect these three dimensions of effectiveness in human–agent collaboration scenarios.

\section{Methods}

This section details the planned empirical study. The goal is to operationalize the conceptual framework and to test how different context handling mechanisms jointly affect collaboration effectiveness. Implementation of the experimental infrastructure has started in the form of prototype agent variants and task scripts.

\subsection{Study design}

The study follows a between subjects design with four experimental conditions that correspond to different context handling strategies in a controlled human–agent collaboration task.

Participants work together with an LLM based agent on a multi step document analysis and synthesis task. Each participant is randomly assigned to one of four agent variants.

\subsection{Experimental conditions}

\begin{enumerate}
  \item \textbf{Long context only.} A single long context LLM agent operates with an extended context window and no external retrieval or explicit long term memory. The full task corpus and dialogue history are provided directly in the prompt up to the context limit.
  \item \textbf{Retrieval augmented generation (RAG).} A smaller context LLM agent uses retrieval from a vector store that contains the task corpus and selected interaction history. For each turn, the system retrieves top-\emph{k} passages based on dense similarity and injects them into the prompt.
  \item \textbf{Summarization focused agent.} An agent maintains a structured summary of the collaboration so far (key findings, decisions, open questions). Before each major step, it presents a concise summary panel to the participant and uses this summary as part of its own context instead of the full history.
  \item \textbf{Sequenced multi agent system.} A simplified Chain of Agents style pipeline in which two worker agents process different parts of the corpus and a coordinator agent synthesizes their outputs. The coordinator maintains a shared memory of intermediate conclusions and uses short local windows for each call.
\end{enumerate}

All conditions use the same base model family to avoid confounding architecture with context handling. Differences lie in how context is assembled and reused.

\subsection{Task}

The planned task is a collaborative analysis and recommendation scenario:

\begin{itemize}
  \item Participants receive a dossier of news articles.
  \item Together with the agent, they must identify key issues, cluster related information and draft a summary for a hypothetical stakeholder.
  \item The task is divided into phases: exploration, synthesis and final recommendation. Each phase involves several chat turns.
\end{itemize}

This structure forces the agent to reuse information over time and to refer back to earlier decisions, which stresses context handling.

\subsection{Participants and procedure}

\begin{itemize}
  \item Target sample: 4-8 participants (preferable more), randomly assigned to conditions.
  \item Each session lasts approximately 30 minutes including instructions and questionnaires.
  \item Procedure:
    \begin{enumerate}
      \item Pre task briefing and informed consent.
      \item Short tutorial on the chat interface and the role of the agent.
      \item Collaborative task with one assigned agent variant.
      \item Post task questionnaire on trust, workload and perceived collaboration quality.
      \item Optional short interview for qualitative feedback.
    \end{enumerate}
\end{itemize}

\subsection{Measures}

To align with the conceptual framework, the study collects measures for the three dimensions of collaboration effectiveness.

\paragraph{Task performance.}
\begin{itemize}
  \item \textbf{Accuracy and coverage:} Expert rating of final recommendations on correctness and coverage of relevant information, using a rubric with several items.
  \item \textbf{Efficiency:} Time to completion and number of turns required to reach the final recommendation.
  \item \textbf{Redundancy:} Share of turns that repeat previously established information or correct earlier misunderstandings.
\end{itemize}

\paragraph{Interaction quality.}
\begin{itemize}
  \item \textbf{Trust in the agent:} Adapted items from trust in automation scales (e.g., perceived reliability and helpfulness).
  \item \textbf{Perceived understanding:} Self report items on how well the agent understood the task and prior context.
  \item \textbf{Usability:} System Usability Scale (SUS) to assess the overall usability of the agent.
  \item \textbf{Behavioural indicators:} Sequence based features such as number of clarification questions asked by the human, frequency of user initiated corrections and presence of instruct–serve–repeat patterns \cite{saqr2025humancollab}.
\end{itemize}

\paragraph{Long-term consistency.}
\begin{itemize}
  \item \textbf{Consistency:} Expert coding of whether the agent contradicts its own earlier statements or decisions across phases.
  \item \textbf{Memory use:} Qualitative coding of instances where the agent correctly or incorrectly reuses earlier context (e.g., referring back to a previous finding).
  \item \textbf{Rationale preservation:} Whether reasons given in earlier phases remain visible and coherent in the final recommendation, inspired by contextual memory intelligence principles \cite{wedel2025cmi}.
\end{itemize}

\section{Analysis Plan}

The analysis will examine how the four context handling strategies affect the three dimensions of collaboration effectiveness and will test the refined research question.

\subsection{Quantitative analysis}

The evaluation follows a between-subjects design where each participant uses only one agent. Comparisons are conducted between groups to identify which context strategy enables the best collaboration.

The analysis considers the following metrics per participant:
\begin{itemize}
  \item \textbf{Objective metrics:} Solution quality, time required, and number of steps.
  \item \textbf{Subjective metrics:} Trust, understandability, and perceived support.
  \item \textbf{Interaction metrics:} Number of clarification questions, corrections, and conversation history.
\end{itemize}

Statistical methods will be applied to detect differences between groups. The expectation is that no single mechanism dominates across all metrics. Sequenced and summarization focused agents may trade small performance differences for better interaction quality, while long context only may excel in accuracy but suffer from higher workload or inconsistency.

\subsection{Sequence and pattern analysis}

\begin{itemize}
  \item Represent each conversation as a sequence of interaction types (instruction, clarification, correction, summarization, exploration).
  \item Use sequence analysis or Markov chain modelling to compare prevalent interaction patterns across conditions, following approaches used in previous work on human–LLM interaction \cite{saqr2025humancollab}.
  \item Identify whether some context handling strategies lead to more collaborative patterns (e.g., more clarification, fewer correction loops) than others.
\end{itemize}

\subsection{Qualitative analysis}

\begin{itemize}
  \item Conduct a thematic analysis of a subset of conversations and post task comments to understand subjective experiences and failure modes that metrics do not capture.
  \item Pay particular attention to episodes where context handling fails (e.g., the agent forgets a key constraint) and how humans react in different conditions.
\end{itemize}

\section{Conclusion and outlook}

This paper updates the project focus in line with feedback that context management and sequencing matter at least as much as raw context window size for human–agent collaboration. Through a targeted review of work from 2024 and 2025, it synthesizes contributions on multi agent sequencing for long context processing, empirical comparisons of retrieval augmented generation and long context models, memory and summarization mechanisms, and studies of human teams with AI support.

The review suggests that effective collaboration depends on how systems structure, retrieve, summarize and preserve context over time, not only on the number of tokens an LLM can process. Multi agent frameworks such as Chain of Agents, Graph of Agents and XpandA show that sequencing and shared memory extend effective context beyond model limits. Industrial and medical studies show that hybrid combinations of retrieval and long context are promising for applied use. Memory surveys and contextual memory intelligence frameworks frame memory as system infrastructure for stable collaboration. Research on human teams highlights that summarization style and interaction patterns influence trust and perceived collaboration quality.

Building on this synthesis, the paper formulates a research question that targets the joint influence of sequencing, retrieval, summarization and context window size on the effectiveness of human–agent collaboration. It proposes a conceptual framework and outlines a comparative study that will operationalize this question through controlled experiments.

The next project phase will refine the experimental design, implement all four agent variants in a unified platform and conduct a pilot study. The final goal is to provide guidance on how to combine context handling mechanisms in LLM based systems so that they function as collaborative partners rather than as obedient yet misaligned assistants.

\begin{acks}
I thank Prof.\ Dr.\ Hanna Moser and Prof.\ Dr.\ Gudrun Socher for their guidance in refining the research question. I used an AI assistant (ChatGPT, GPT-5.1~Thinking) only for language polishing. All conceptual decisions, interpretation of the literature and the final research design are my own.

This work forms part of the main seminar on human–agent collaboration at Munich University of Applied Sciences.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{software}

\end{document}
